# -*- coding: utf-8 -*-
"""CodingAssignment1_anj2393.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14bEyUe83rmHKN7xuwSTXL1REAT2A-Gmd

To begin, we need to install and import BeautifulSoup and Pandas libraries if not already available. Try to import the libraries and if successful, print a success confirmation message. If not successful, install both libraries, import them, and print a success message for installation and importing.
"""

try:
    from bs4 import BeautifulSoup
    import pandas as pd
    print ("BeautifulSoup and Pandas are already installed and imported")
except:
    import sys
    !conda install --yes --prefix {sys.prefix} bs4
    !conda install --yes --prefix {sys.prefix} pandas
    from bs4 import BeautifulSoup
    import pandas
    print ("BeautifulSoup and Pandas were not found. Installed them and imported")

import requests

"""Find the webpage that you'd like to scrape data from.

*   Initialize a BeautifulSoup object to read and parse the webpage of your choice
*   Print a success message when successfully loaded and parsed.
"""

opened_webpage = requests.get("https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population")
print ("Webpage opened successfully...")

bs = BeautifulSoup(opened_webpage.content, "html.parser")
print ("Webpage loaded and parsed successfully...")

"""Scrape the raw data from the webpage.

*   Define a list where the raw data will be kept.
*   Create a table and find the table on the webpage, use the index if there are more than one table on the page to scrape from the appropriate one.
*   Read the table line by line using a for loop and append each row's data to the raw_data list.
*   Print the raw_data list



"""

# Define an empty list where the data will be kept
raw_data = []

# Find all the tables in the webpage page that we have just parsed
table = bs.find_all("table")[4]

for row in table:
    line = row.text
    raw_data.append(line)

print(raw_data)

"""Clean the data
*   Define the column names in a new list containing all column names from the table. Rename them as necessary or relevant for data interpretation.
*   Create an empty list for final data.
*   Find data for columns by looking through the webpage's html and appropriate html tag, which contains all the data for columns.
*   For each row, read through the data and strip data and append to that row's data
*   Create a Pandas dataframe for the final data and set column names to previously defined list of column names
*   Show dataframe
"""

column_names = ["City",
           "State", "2022 Estimate",
           "2020 Census","Percent Change",
           "2020 land area in sq mi", "2020 land area in sq km", "2020 population density per sq mi",
           "2020 population density per sq km","Location"]
final_data = []

column_data = table.find_all("tr")

for row in column_data:
  row_data = row.find_all('td')
  individual_row_data = [data.text.strip() for data in row_data]
  final_data.append(individual_row_data)

final_data = pd.DataFrame(final_data)
final_data.columns = column_names
final_data

"""* Check for duplicates and print amount of duplicates existing in the final data
*   Delete duplicate rows from final data
*   Print message displaying amount of duplicates after deleting duplicates, which should be 0


"""

number_of_duplicates = final_data.duplicated().sum()
print (f" Number of duplicates before : {number_of_duplicates}")

# Delete duplicate rows
final_data = final_data.drop_duplicates()

number_of_duplicates = final_data.duplicated().sum()
print (f" Number of duplicates after removing : {number_of_duplicates}")

"""*   Inspect the data and check for any noisy entries.
*   Check to make sure that the number of entries is equal to number of non-null entries.
"""

final_data.info()

"""There are 334 rows but 333 non-null entries, so we delete the row with NULL entries. Inspect info to ensure that all NULL entries were deleted."""

final_data = final_data.dropna()
final_data.info()

"""Additional transformations:
*   Define a function to clean and convert strings
*   Use the .replace action to replace or remove any unnecessary strings and convert the columns into floats
*   Use the import string to import the alphabet lowercase in order to remove superscript text next to city names and clean data
*   Display final data


"""

import string

def clean_string_and_convert(s):
    s = str(s).replace("\xa0sq\xa0mi","")
    s = str(s).replace(",","")
    s = str(s).replace("\xa0km2","")
    s = str(s).replace("/sq\xa0mi","")
    s = str(s).replace("/km2","")
    for c in string.ascii_lowercase:
      s = str(s).replace("["+c,"")
    s = str(s).replace("]","")
    s = str(s).replace("%","")
    converted = s
    return converted

final_data["City"] = final_data["City"].apply(clean_string_and_convert)
final_data["2022 Estimate"] = final_data["2022 Estimate"].apply(clean_string_and_convert).astype(float)
final_data["2020 Census"] = final_data["2020 Census"].apply(clean_string_and_convert).astype(float)
final_data["Percent Change"] = final_data["Percent Change"].apply(clean_string_and_convert)
final_data["2020 land area in sq mi"] = final_data["2020 land area in sq mi"].apply(clean_string_and_convert).astype(float)
final_data["2020 land area in sq km"] = final_data["2020 land area in sq km"].apply(clean_string_and_convert).astype(float)
final_data["2020 population density per sq mi"] = final_data["2020 population density per sq mi"].apply(clean_string_and_convert).astype(float)
final_data["2020 population density per sq km"] = final_data["2020 population density per sq km"].apply(clean_string_and_convert).astype(float)

final_data

"""Store the DataFrame table created on the local disk as a .csv file to be used later using Pandas dataframes."""

final_data.to_csv("List_of_United_States_Cities_by_Population.csv")

"""Read the csv just saved and load back as a dataframe."""

US_cities_df = pd.read_csv("List_of_United_States_Cities_by_Population.csv")

"""Import libraries scipy and pyplot for data visualizations."""

## Import libraries
## if you see any import error, install libraries through pip install command
import scipy
from matplotlib import pyplot as plt
print ("Imported all libraries successfully...")

"""To study the association between two variables, calculate the correlation coefficient.
*   Import pearsonr from scipy.stats
*   Calculate the coefficient using the two columns/variables that we want to compare

Below we see a weak correlation between 2020 census population and 2020 land area in square miles.2020 census population and the land area are not very strongly correlated at 0.3636 showing a weaker positive correlation, indicating that a greater land area does not necessarily result in greater population.



"""

from scipy.stats import pearsonr

p = pearsonr(US_cities_df["2020 Census"],US_cities_df["2020 land area in sq mi"])
print (p[0])

"""Create a scatterplot to compare 2020 Census population data and 2020 land area in square miles.
*   Define both columns and their associated column in the dataframe
*   Use the plt.scatter to compare both columns and define the marker
*   Define the x and y-axis labels, along with their units, for the scatterplot graph, as well as the plot title

"""

population_column = US_cities_df["2020 Census"]
land_column = US_cities_df["2020 land area in sq mi"]

plt.scatter(population_column,land_column, marker="*")

plt.xlabel("2020 Population (millions)")
plt.ylabel("Land Area (in sq mi)")

# We can add a title too
plt.title("population-vs-land area in 2020")

"""As predicted by our correlation coefficient above, there does not seem to be a strong correlation between population and land area as shown by the spread of the points on the plot. There are also a few outliers, either with a large land area and small population or vice versa. There is a visible concentration of smaller cities that have similar populations and land areas.

Print the census population and obtain some basic descriptive statistics about a column from the dataframe that will then be used to help interpret a boxplot.
"""

census_population = US_cities_df["2020 Census"]
print (census_population)
census_population.describe()

"""Create a boxplot to find the summary of the dataset for a specific variable, in this case, 2020 census population data.
*   Define the variable/column that you want the boxplot to plot
*   Define the x and y-axis labels, along with their units, for the scatterplot graph, as well as the plot title

"""

population_column = US_cities_df["2020 Census"]

plt.boxplot(population_column)

plt.xlabel("2020 Census")
plt.ylabel("Population in millions")
plt.title("2020 Census Population Data")

"""In the boxplot, we can see that first to third quartiles remain between 0 and 100,000 people in cities, and there are a few outliers above 200,000 people and only one outlying city, which is also the maximum, with a population over 800,000 people.Population generally skews towards the minimum compared to the maximum, making the maximum and larger values outliers."""